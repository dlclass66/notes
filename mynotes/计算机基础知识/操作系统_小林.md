
# 硬件结构

## cpu是如何执行程序的

### 冯诺依曼模型

计算机基本结构为5个部分 运算器，控制器，存储器，输入设备，输出设备

### 内存

基本单位byte字节 1byte = 8 bit（位）

### cpu

32位处理器一次处理4个字节（32位） 64位一次处理64位
32位最大操作4g内存 （2^32 byte）
软件的位宽指指令的位宽
一般64位的电脑可以运行32位的程序 反之则不行
常见寄存器

1. 通用寄存器 用来存放需要计算的数据
2. 程序计数器 存储下一条指令的地址
3. 指令寄存器 存储正在执行的指令

### 总线

用于通信
有以下几种

1. 地址总线 用于指定地址
2. 数据总线 用于读写数据
3. 控制总线 用于发送和接收数据

### cpu执行程序的大致过程

读取程序计数器对应的指令存入指令寄存器， 程序计数器自增（增大多少取决于cpu的位数） cpu执行指令寄存器中的指令 然后继续第一步
数据和指令在内存中是分开存放的 指令放在正文段 数据放在数据段
现代cpu多采用流水线的方式执行指令 一条指令被分为4个阶段 称为4级流水线

1. fetch cpu通过程序计数器读取指令
2. decode 对指令进行解码
3. execution 执行指令
4. store 将计算结果回写寄存器或者将寄存器的值写入内存
这4个阶段称为指令周期

### 指令类型

1. 数据传输
2. 运算
3. 跳转（用来实现条件分支 函数调用等）
4. 信号类型（比如中断trap）
5. 闲置（执行后cpu空转）

### 执行速度

cpu参数有时钟频率 表示一秒cpu能完成的基本动作的数量 但一条指令不一定只对应一个基本动作

## 磁盘与内存

### 存储器结构

离cpu由近到远 速度由快到慢 容量由小到大 寄存器 cpu cache（l1, l2, l3）内存 硬盘
32位cpu中大多数寄存器可以存储4字节 64位中大多数可以存储8字节
l1缓存通常分为指令和数据两个部分 每个核心都有 l2缓存每个核心都有 l3缓存通常多个核心共用
cpu并不会直接和每一种存储设备打交道 每种存储设备只和其相邻的设备交互 相当于层层缓存

## 如何写出让cpu运行更快的代码

对于计算密集型的程序来说 cpu运行效率很重要 让cpu计算所需要的数据能尽可能的在cpu cache中而不是内存中可以提高效率

### cpu cache的数据结构和读取过程

cache line（缓存块）是cpu从内存读取数据的基本单位 由标志（tag） 和数据块（data block）组成
cpu读取数据时 会先访问cache 没有命中再访问内存 这里就存在一个问题 cpu如何确定要访问的数据在不在cache中
最简单是使用直接映射 内存块对应的cache line由取模决定 唯一确定 但是这样可能出现多个内存块映射到同一个cache line上 为了区别不同的内存块 在对应的cache中还会存储一个tag 而cpu从cache中读取数据时 并不是读取整个cache 而是读取数据片段 （字word）这就需要一个偏移量

### 提高数据命中率

连续的访问 可以提高缓存命中率

### 提高指令命中率

分支中有规律的话 cpu会提前预测 这样也可以提高命中率

### 多核

由于l1 l2 不是多核心共享的 所以对于计算密集型 为了让缓存命中率更高 最好限制在一个核心上运行

## cpu缓存一致性

### cpu cache的数据写入

数据写入cache 导致内存与对应的cache中的数据不同 所以必须要把cache中的数据同步到内存中
有以下两种方法

1. 写直达（write through）
2. 写回（write back）

#### 写直达

最简单的方法 把数据同时写入内存和cache中
写入前如果数据已经在cache中了 就先更新cache 再写到内存中
如果没有在cache中 就直接把数据更新到内存里
直观 简单 但问题是每次操作都要写回到内存 性能受影响

#### 写回

当发生写操作时，新的数据仅被写入cache block中 只有当被修改过的cache被替换时才需要写到内存中 减少了数据写回内存的频率
具体做法

* 当cpu发生写操作时 如果cache里面有需要修改的数据 则修改 然后标记为脏
* 如果对应的cache存储的是其他内存块 这个时候就需要替换了 如果是脏的就写回内存 否则就不需要 然后把要写入的数据读取到cache中 修改并标记为脏

### 缓存一致性

如果使用写回策略 多核心操作同一变量就会出现问题 比如一个核心执行了i++ 只更新了cache而没有写回内存 另一个核心读取到的i的值就是错误的
要解决这一问题就需要同步不同核心的缓存 需要以下两点

1. 某个核心的cache数据更新需要传播的其他核心（写传播 write propagation）
2. 某个核心对数据的操作顺序，必须在其他核心看起来一样 事务串行化（transaction serialization） 比如核心a和b同时更新了i 传播到cd核心 而cd中ab更新顺序不同 就会产生错误
所以第二点需要锁 如果两个核心的cache有相同数据 那么对于这个相同数据的更新 需要拿到锁才能进行

### 总线嗅探

为了实现写传播 某个核心更新了cache需要广播 每个核心都会监听总线上的广播事件 如果有对应数据在自己的cache中 就更新 这种方法很简单 但是会加重总线的负担 也无法实现事务串行化

### mesi协议

基于总线嗅探机制 实现了事务串行化 用状态机制降低了总线带宽压力 做到了缓存一致性
用4个状态标记了cache line

1. 已修改 就是脏数据 修改也无需广播
2. 独占 干净数据 并且只有一个cache中有 可以自由操作 不需要通知其他核心 其他核心从内存中也读取了同样的数据就变成共享
3. 共享 干净数据 在多个cache中有 修改时需要广播 把其他cache中的相同数据设置为无效 然后再更新 变为已修改
4. 无效 数据已经失效 不可读取
只有修改3状态的数据才需要广播 减低了总线负担
运用了有限状态机的思想

## cpu是如何执行任务的

### catch伪共享

多个线程同时读写同一个cache line的不同变量，导致cpu cache失效的现象 （cache line会被标记为共享）性能受到影响

### 避免方法

对于多个线程共享的热点数据 即经常修改的数据 要避免恰好在一个cache line中
linux中有一个宏（__cacheline_aligned_in_smp）用于解决伪共享问题 在多核cpu中可以让变量对齐cache line 使其不会出现在同一个cache line中 这样就用空间换了时间
应用层也有解决办法 可以用一些空白填充不会被修改的数据的前后

### cpu是如何选择线程的

在linux中 进程和线程都是用 task_struct 结构体表示的 区别在于 线程的结构体内的一些资源是共享进程已经创建的资源 如代码段等 所以线程也被称为轻量级进程
线程进程统称为任务
linux中根据任务优先级及响应要求 主要分为两种 优先级数值越小 优先度越高

1. 实时任务 要尽可能快的执行 优先级0 ~ 99
2. 普通任务 没有很高要求 100 ~ 139

#### 调度类

为了保障高优先级的任务能够尽可能早的执行

#### 完全公平调度

我们遇到的基本都是普通任务 公平性很重要 linux中有一个基于cfs（完全公平调度）的调度算法
它为每一个任务安排一个虚拟运行时间 在运行的程序 运行得越久 虚拟时间就越大 没有运行的 虚拟运行时间不变 调度的时候会优先选择虚拟运行时间小的 考虑到 优先级 还需要加权 让优先级高的虚拟运行时间短

#### cpu运行队列

每个核心都有自己的任务队列
完全公平调度对应的队列是用红黑树实现的 按虚拟运行时间排序

#### 调整优先级

启动任务 默认是普通任务 可以通过调整nice值调整优先级 但是仍然是普通任务 如果要进一步调整 就要改变任务的优先级和调度策略 使其变为实时任务

## 软中断

### 中断是什么

系统响应硬件设备请求的一种机制 操作系统收到请求后 会打断正在执行的程序 调用中断处理程序响应请求
中断是一种异步事件处理机制 可以提高系统的并发能力 中断处理程序要尽可能快的执行完 减少对正常进程运行调度的影响 而且 中断处理程序响应中断时 可能会临时关闭中断 这时系统的其他中断请求都无法被响应 可能会丢失中断

#### linux软中断

linux为了解决中断处理程序执行过长和中断丢失的问题 将中断过程分为了两个阶段

1. 上半部分快速处理中断 一般会暂时关闭中断请求 主要负责处理跟硬件紧密相关或者时间敏感的事情
2. 下半部分延迟处理上半部为完成的工作 以内核线程的方式运行

也可以理解为

1. 上半部直接处理硬件请求 也就是硬中断 主要负责耗时短的 特点是快速执行
2. 由内核触发 软中断 负责上半部未完成的工作 耗时较长 延迟执行
所以硬中断会打断cpu正在执行的任务 然后立即执行 而软中断是以内核线程的方式运行 每一个cpu核心对应一个软中断内核线程 一些内核自定义事件也属于软中断

#### 系统中的软中断

软中断是以内核线程的方式运行的 所以用ps命令（显示当前运行进程的状态 类似windows的任务管理器）可以看到  内核线程的名字外面都有中括号 因为ps无法获取他们的命令行参数 所以一般来说 名字在中括号里面的都可以认为是内核线程

#### 如何定位软中断cpu使用率过高的问题

要想知道当前的系统的软中断情况 我们可以使用top命令查看 si代表软中断 可以得到cpu软中断的使用率 根据不同类型软中断的中断次数变化速率可以确定哪种软中断占比最高 比如web服务器就可以分析哪个网卡对应的中断最多 再抓包分析

## 负数 小数的表示

### 负数用补码表示

int 32位 最高位是符号标志位 0表示正数 1表示负数 剩下31位表示2进制数据
负数是以补码表示的 就是把其对应的正数（绝对值）二进制全部取反再加1
使用补码的方式在进行加减法时 直接用二进制的规则即可 提高了运算的效率 所以补码就相当于用0 减去其绝对值

### 小数用浮点数

一种表示方法是使用定点数 小数点后第一个二进制位表示2的-1次方 但是有很多小数无非被这样表示
计算机采用浮点数的方式（类似科学计数法）比如1000.101（二进制定点数）写为浮点数就是 1.000101 * 2 ^ 3 最关键的是000101和3 000101称为尾数 3称为指数 然后还需要一个符号位
符号位表示正负 0为正 1为负 指数位长度决定了数值的表达范围 尾数位长度决定了数值的精度
32位的浮点数为单精度 float 64位的是双精度 double
指数在存储过程中会加上一个正的偏移量 用无符号整数存储
因为有的十进制小数无法转换为精确的二进制定点数 所以小数在计算机中是近似的

# 操作系统结构

## linux内核和windows内核

### 内核

内核是应用和硬件的中间层 让应用只需要和内核交互 而无需关心硬件 降低了开发难度
现代操作系统 内核一般会提供4大基本能力

1. 进程调度 决定哪个进程使用cpu
2. 内存管理 决定内存的分配与回收
3. 管理硬件 为进程与硬件间提供通讯能力
4. 提供系统调用 用户程序通过这个方式与系统交互

为了安全 内核的权限很高 可以控制硬件 而应用程序权限小 内存被分为两个区域 内核空间（只有内核才有权访问）和用户空间（专门给用户程序使用）
在内核空间称为内核态 在用户空间称为用户态 应用程序如果需要进入内核态 就需要系统调用
过程 应用程序使用系统调用时 产生中断 cpu运行中断处理程序 也就是开始执行内核处理程序 处理完后 主动触发中断 回到用户态

### linux

基于c语言 开源
内核设计理念主要有以下几点

1. multitask 多任务
2. smp 对称多处理
3. elf 可执行文件链接格式
4. monolithic kernel 宏内核

#### 多任务

多任务表示多个任务可以并发或并行执行 每个任务执行一小段时间就切换到另一个任务 宏观来看一段时间执行了多个任务 这叫并发
多个任务被不同cpu同时执行 这叫并行

#### smp 对称多处理

代表每个cpu核心地位相等 每个核心都可以访问完整的硬件资源
每个程序都可以被分配到任意一个cpu核心上执行

#### elf

是linux中可执行文件的存储格式 elf将文件分段
elf的生成
我们编写的代码 首先通过编译器变成汇编代码 然后通过汇编器变成目标代码 最后通过链接器 把多个目标文件及调用的各种函数库链接起来 形成elf文件
elf的执行
通过装载器把elf装载到内存中 然后取指执行

#### 宏内核

linux内核是一个完整的可执行程序 并且拥有最高权限
特征 系统内核所有模块 如进程调度 内存管理等都运行在内核态
但是linux也实现了动态加载内核模块的功能 比如大部分驱动就是动态加载的 与内核其他模块解耦 让驱动开发与加载更为方便灵活
与其相反的是微内核
内核只保留最基本的能力 而其他的被放到了用户空间 比如驱动程序 文件系统 这样服务与服务之间是隔离的 单个服务出现故障不会导致整个操作系统崩溃 提高了操作系统的稳定性和可靠性
微内核功能少 可移植性高 但是不好的地方在于 由于驱动不在内核中 而驱动需要频繁与硬件交互 这就需要频繁切换到内核态 带来了系统损耗 鸿蒙就是微内核
还有一种是混合内核 架构有点像宏内核包裹着一个微内核

### windows

Windows的内核叫Windows nt
windows和linux一样 也支持multitask和smp 但是不同的是 windows的内核设计是混合型的 可执行文件的格式也不同 Windows的可执行文件格式叫pe 扩展名通常是.exe .dll .sys等

# 内存管理

## 为什么需要虚拟内存

单片机没有操作系统 cpu直接操纵内存物理地址 很麻烦 还可能互相冲突
操作系统把进程所使用的地址隔离开 每个进程有自己的虚拟地址空间 而虚拟地址到物理地址的映射由操作系统完成（cpu的mmu芯片） 对应用透明
有两种管理方式 内存分段和分页

### 内存分段

分段较早提出 程序是由若干个逻辑分段组成 代码分段 数据分段 栈段 堆段  
分段机制下 虚拟地址由两部分组成 段选择因子和段内偏移量
段选择子保存在段寄存器里面 最重要的是段号 用作段表的索引 段表里面保存了段的基地址 段的界限和特权等级
段内偏移量 如果段内偏移量是合法的 物理内存地址就是段基址加上偏移量  
分段的不足之处

1. 内存碎片
2. 内存交换效率低

#### 内存碎片

可分为内部碎片和外部碎片
内存分段管理可以根据段实际需求分配内存 所以不会有内部碎片 但是由于段的长度不固定 会产生多个不连续的小物理内存 出现外部碎片
可以使用内存交换解决外部碎片问题 linux就有swap分区 可以通过把内存写入swap分区 再写回内存 以更合理的方式排列 但是对与多进程的系统来说 外部碎片很容易产生 而swap需要用到硬盘 存在很大性能瓶颈

### 内存分页

可以少出现一些碎片 当需要内存交换时 交换的数据也更少一点
分页是把整个虚拟和物理内存空间切成一段段固定大小的空间 被称为页 linux下页的大小为4kb
虚拟地址和物理地址通过页表来映射 页表存储在内存中 mmu(内存管理单元)做地址转换的工作
当进程访问的虚拟地址在页表中查不到时 系统会产生一个缺页异常 进入内核态分配物理内存 更新进程页表 在回到用户态 恢复进程运行
分页是如何解决外部碎片和内存效率低的问题的
分页时 每个页固定大小 相邻紧密排列 不会有外部碎片
但是会有内存浪费的现象（内部碎片）因为进程使用的物理内存的最小单位是页  
当内存空间不够时 操作系统会把内存中最近没被使用的页暂时写到磁盘（换出）需要的时候再加载到内存（换入）这样就减少了需要内存交换的数据量 提高了内存交换的效率
加载程序时 我们也不需要一次就把程序加载到内存中 只加载需要用到的虚拟内存页即可
虚拟地址和物理地址的映射
虚拟地址分为两部分 页号和页内偏移 页号是页表的索引 页表包含了每页在物理内存的基地址 基地址和页内偏移就形成了物理地址
简单分页的缺陷
主要是空间问题 操作系统可以同时运行非常多的进程 假设32位环境下 虚拟地址空间共4g 而一个页的大小是4k 假设每个页表项要4个字节 则4g的空间需要4m内存存储页表 而每个进程极限情况下都需要这么大的空间存储页表

#### 多级页表

可以把页表项也进行分页 比如二级页表的虚拟地址包括 一级页号 二级页号 页内偏移 通过一级页号到对应的页表寄存器中得到二级页表地址
通过二级页号和二级页表得到 最终的物理内存页地址
如果4g虚拟地址全部映射到物理内存上 二级分页占用的空间其实更大 但是我们往往不会分配那么多空间 然后如果某个一级页表的页表项没有被用到 就不需要创建其对应的二级页表了  
分页的页表必须覆盖全部的虚拟内存地址 （因为虚拟地址在页表中找不到对应的项，系统就无法工作）单级页表必须给每个分页一个页表项 而多级分页靠第一级分页就可以覆盖整个虚拟内存空间了
64位系统 需要4级目录

#### tlb

多级页表解决了空间上的问题 但是由于增加了地址转换的流程 也就增加了时间上的开销
由于程序具有局部性 所以可以把最常访问的几个页表存储到访问速度更快的硬件 cpu中有一个专门存放程序最常访问的页表项的cache 也就是tlb 通常被称为页表缓存 转址旁路缓存 快表等
tlb的命中率其实很高

### 段页式内存管理

分页和分段并不是对立的 可以组合起来在同一个系统中使用 被称为段页式内存管理
实现方式

1. 先将程序划分成多个有逻辑意义的段  
2. 再将每个段划分成页

这样 地址结构就由段号 段内页号 页内偏移组成
每个程序有一个段表 每个段有一个页表 段表中的地址是页表的地址 页表的中存储了每个页号对应的物理页号
要得到物理地址需要三次内存访问

1. 访问段表
2. 访问页表
3. 根据物理页号和页内偏移访问物理地址

可用软硬件结合的方式实现段页式地址变换 虽然增加了硬件成本和系统开销 但是提高了内存利用率

### linux内存布局

#### intel处理器的内存管理

早期使用段式内存管理 后实现了页式内存管理 但是页式内存管理的作用是在由段式内存管理所映射的地址上在加上一层地址映射  
程序使用逻辑地址 通过段内存管理变为（线性地址）虚拟地址 然后通过页内存管理映射为物理地址

#### linux的内存管理

主要采用页式 也涉及了段式
因为intelx86cpu 会先段式映射 但是linux中的每个段都是从0地址开始的整个4g虚拟空间（32位）也就屏蔽了处理器中的逻辑地址概念 段只用于访问控制和内存保护

#### linux虚拟地址空间的分布

被分为内核空间和用户空间 一般内核空间占据高位 在用户态只能访问用户空间 内核态才可以访问内核空间  
虽然每个进程有自己独立的虚拟内存 但是其内核地址关联的都是相同的物理内存 这样可以让进程切换到内核态后 更方便的访问内核空间内存

#### 用户空间分布情况

以32位为例 从低到高分别是六种不同的内存段

1. 代码段 包括二进制可执行代码
2. 数据段 包括已初始化的静态变量和全局变量
3. bss段 未初始化的静态变量和全局变量  
4. 堆段 动态分配的内存 从低开始向上增长
5. 文件映射段 包括动态库 共享内存等 从低地址向上增长 （跟硬件和内核版本有关）
6. 栈段 包括局部变量和函数调用的上下文 栈的大小是固定的 一般为8mb 当然也可以自定  

代码段下还有一段保留区 因为在大多数系统中 较小数值的地址被认为不合法 比如在c代码中 无效的指针会被赋值为NULL 有了不可访问的内存保留区 就可以处理这些情况
在这7个内存段中 堆和文件映射段是动态分配的 malloc（）可以在堆动态分配内存 mmap（）可以在文件映射段动态分配内存

### 虚拟内存的作用

1. 进程可以运行 即使其总内存超过物理内存大小 通过swap
2. 解决了多进程之间的地址冲突
3. 页表中的页表项除了物理地址外 还可以标记页属性 提供了更好的安全性

## malloc 是如何分配内存的

malloc（）并不是系统调用 而是c库中的函数 
malloc申请内存时 有两种方式向操作系统申请堆内存

1. 通过brk（）系统调用 （堆）
2. 通过mmap（）系统调用 （文件映射区）

方式一实现很简单 就是将堆顶指针向上移动（高地址）
方法二 通过mmap（）中的私有匿名映射方式 在文件映射区 分配了一片内存
对于小内存 一般用brk（）（方式一） 大的用mmap（）（方式二）

### malloc分配的是物理内存吗

不是 malloc分配的是虚拟内存 如果分配后的虚拟内存没有被访问的话 虚拟内存就不会映射到物理内存 这样就不会占用物理内存
访问已分配的虚拟内存地址时 操作系统通过查找页表 发现虚拟内存对应的页没有在物理内存中 就会触发缺页中断 然后操作系统会建立虚拟内存和物理内存之间的映射关系

### malloc（1）会分配多大的虚拟内存

malloc分配空间时 并不会老老实实按用户要求分配 而是会预分配更大的空间作为内存池 具体分配多大与malloc使用的内存管理器有关

### free释放内存 会归还给操作系统吗

free释放内存后 堆内存还是存在 并不会归还给操作系统 因为与其把内存释放 还给操作系统 不如先缓存着 放入malloc的内存池中 当进程再次申请时就可以直接复用  
当进程退出后 操作系统才会回收进程的所有资源  
上面所说的针对brk（）方法得到的内存 如果是mmap方法 free释放后就会直接还给操作系统

### 为什么不全部使用mmap

因为分配内存需要系统调用 用户态和内核态的切换会消耗不少资源 另外 因为mmap每次释放内存时都会归还给操作系统 所以每次mmap分配的虚拟内存都是缺页状态 第一次访问都会触发缺页中断 这些都会造成很大的cpu消耗 而brk方法有内存池 减少了系统调用和缺页中断的次数

### 为什么不全部使用brk

因为brk不会马上释放 所以频繁的malloc和free会产生越来越多的内存碎片 （内存泄漏） 而且很难检查出来
所以brk和mmap要配合使用

### free只传入了内存地址 为什么可以知道要多大的内存

malloc给用户态的内存起始地址比堆空间起始地址多了16字节（相当于有16字节并不能被用户使用） 这16字节保存了该内存块的描述信息 比如该内存块的大小
当执行free函数时 free会对传进来的地址偏移16个字节 从这16个字节中得到内存块的大小  

## 内存满了 会发生什么

### 内存分配的过程是怎样的

1. malloc申请到虚拟内存
2. 应用程序读写到该内存时 产生缺页中断
3. 缺页中断处理函数查看是否有空闲的物理内存 有的话就直接分配 建立映射关系  
4. 没有的话 内核就进行内存回收 主要有两种方式 直接内存回收和后台内存回收

后台内存回收（kswapd）在物理内存紧张时 唤醒kswapd内核线程回收内存 这个过程是异步的
直接回收内存（direct reclaim）如果后台异步回收跟不上进程内存申请的速度 就会直接回收 这个过程是同步的
如果直接回收内存后 空闲的物理内存仍然无法满足要求 内核就会触发oom机制
oom killer机制会根据算法选择一个内存占用较高的进程 杀掉 如果还不够就继续选择然后杀掉 直到足够

### 哪些内存可以被回收

主要有两类 回收方式也不同

1. 文件页 内核缓存的磁盘数据和文件数据叫文件页 大部分文件页 都可以直接释放内存 有需要时 再从硬盘重新读取就可以 而脏页就得先写入硬盘 才能进行内存释放  
2. 这部分内存没有实际载体 不像文件缓存有硬盘文件这个载体 比如堆，栈数据等 这部分内存很可能还会被再次访问 所以不能直接释放内存 这类文件回收方式是通过swap  

文件页和匿名页的回收都是基于lru算法 也就是优先回收不常访问的内存 lru算法实际维护着 active和inactive 两个双向链表
active_list 活跃内存页链表 存放最近被访问过的（活跃）的内存页
inactive_list 不活跃内存页链表 存放的是很少被访问的（非活跃）的内存页
越接近链表尾部 表示内存页越不常被访问 这样在回收内存时 系统就可以优先回收不活跃的内存  

### 回收内存带来的性能影响

回收内存基本都会发生磁盘i/o 势必会影响系统性能  
下面是一些常见解决方案

#### 调整文件页和匿名页的回收倾向

文件页的影响会相对较少 因为干净页不需要写回硬盘 而匿名页swap换入换出都会发生磁盘i/o
linux提供了一个选项 可以调整文件页和匿名页的回收倾向 可以尽量回收文件页

#### 尽早触发kswapd内核线程异步回收内存

系统抖动 而且抖动时应用程序每秒直接扫描的页的数值很大 大概率就是因为直接回收内存导致
针对这个问题 解决方法是尽早触发后台内存回收 避免应用程序直接内存回收
触发后台内存回收的条件  
内核设置了三个内存阈值（水位）用来衡量当前剩余内存充裕或者紧张  

1. 页最小阈值
2. 页低阈值
3. 页高阈值

这三个内存阈值会划分为4种内存使用情况
剩余内存大于3 则内存充足 23之间 内存分配正常 12之间 内存压力大 小于1 内存基本耗尽
kswapd会定期扫描内存 根据剩余内存情况来进行回收工作
第12情况都无需操作 第三种情况kswapd0会执行内存回收 直到变为情况1 第4种情况会直接触发直接回收
页最小阈值可以直接设置 页高阈值和页低阈值和其是线性关系 由固定公式计算得出  
为了尽早回收 可以适当增大页最小阈值 但是这样会让可用内存降低

#### numa架构下的内存回收

smp架构 多个cpu共享资源的架构 每个cpu地位平等 也被称为一致存储访问架构 但是随着cpu处理器核数的增多 多个cpu通过一个总线访问内存 总线的带宽压力会越来越大 每个cpu的可用带宽会越来越小  
为了解决这个问题 就研制出numa结构 即非一致存储访问结构  
numa将cpu分组 每一组cpu用node表示 一个node可能包含多个cpu 每个node有自己独立的资源 每个node通过互联模块总线通信 所以每个node上的cpu还是可用访问到整个系统中的所有内存 但是访问远端的node内存比访问本地内存要耗时很多
与内存回收的关系  
当某个node内存不足时 可以从其他node寻找内存 也可以从本地中回收内存 可以控制 有以下几种选项

1. 默认 回收本地内存前 在其他node寻找空闲内存  
2. 只回收本地内存
3. 只回收本地内存 将脏页写回硬盘 回收  
4. 只回收本地内存 采用swap方法  

虽然访问远端耗时多 但是相比内存回收还是很小 一般选择第一种方案

### 如何保护进程不被oom杀掉

选择被杀进程的标准 进程已经使用的物理页面数 越大越容易被杀掉 还有一个可以手动设置的校准值 可以通过修改校准值让一个进程不可能被杀掉 可以将重要的系统服务进程设置为不可被杀掉 最好不要把业务程序设置为不可被杀掉  

## 在4gb物理内存的机器上申请8gb内存

