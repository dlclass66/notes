# 认识redis

## 与memcached区别

redis的优势

1. 支持的数据类型更丰富
2. 支持持久化
3. 原生支持集群
4. 支持订阅发布模型， lua脚本， 事务

## redis作为缓存的原因

1. 高性能 数据在内存 读写速度快
2. 高并发 每秒请求数大约为mysql10倍

# redis的数据结构

## 种类及应用场景

常见5种 后续又有4种
能实现交并补的 set zset用来热搜
bitmap 二值状态统计 比如登录状态
hyperloglog 海量数据基数统计
geo 存储地理位置信息 比如滴滴
stream 消息队列

## 常见5种实现

### string

sds 简单动态字符串
相对于c字符串有以下优点

1. 可以保存任意二进制数据
2. 获取字符串长度复杂度为常数时间
3. 安全 拼接不会溢出

### list

最新的使用quicklist 一个一个小的压缩链表像双向链表一样连接而成
类似deque ziplist空间连续

### hash

较小的采用listpack（对ziplist的改造） 大的采用散列表

### set

数量较少且元素都是整数 采用整数集合 其他采用hash表

### zset

数量少采用listpack 其他采用跳表

# redis线程模型

## 单线程

单线程是说redis完成客户请求是由一个主线程完成的
但是redis程序有后台进程  关闭文件 aof刷盘 异步释放redis内存都是子进程完成的（大key使用unlink异步删除）
后台线程是消费者 生产者把耗时任务丢到任务队列中 后台线程不断轮询 有任务就拿出来执行

## redis单线程模式

epoll 三种事件 连接事件 读事件 写事件 和web服务器有很多类似的地方
参考小林code

## redis单线程为什么这么快

单线程网络io和执行命令的原因

1. 大部分操作在内存 cpu不是瓶颈
2. 单线程避免了很多多线程的问题 比如死锁 线程切换开销
3. 使用了io多路复用 可以同时监听多个套接字
如果想利用服务器的多核cpu可以启动多个节点

## redis6.0之后的多线程

为了提高网络io效率 网络io操作使用了多线程

# redis持久化

## 如何实现数据不丢失

三种方式

1. aof 记录操作（写）
2. rdb 快照
3. 混合 由上述两种的优点

## aof

### 先执行命令再将命令记录到aof日志

好处

1. 避免检查语法的开销（如果把语法错误的命令写入aof可能会出错）
2. 不会阻塞写操作命令

缺点

1. 数据可能丢失
2. 可能阻塞其他操作 因为aof日志也是在主线程执行

### 写入过程

1. 命令追加到用户态缓存区
2. 通过write（）系统调用 拷贝到内核缓冲区
3. 由内核决定什么时候落盘

第三步有三种策略

1. always 每次执行完写操作就落盘 对性能影响大
2. everysec 每秒写一次盘 常用
3. no 由操作系统控制 一般约为30s一次

### aof过大的重写

参考当前数据库状态重新生成aof
过程 使用子**进程**（fork出）bgrewriteaof
两点好处

1. 不会阻塞主进程
2. 不用线程 因为线程共享内存 需要加锁 进程共享内存但是只读 修改时发生写时复制 不用加锁

重写过程中主进程处理命令造成的数据不一致
解决方案
重写过程中再开辟一个aof重写缓冲区 redis执行完一个写命令后 会把命令同时写入aof缓冲区和aof重写缓冲区 子进程执行完重写后向主进程发送信号 主进程再把aof重写缓冲区的内容追加到aof文件中

## rdb

记录一个瞬间的内存数据 比aof更快（恢复）
save 手动 主线程
bgsave 手动 子进程
save m n 自动 子进程
执行快照时数据可修改 因为是子进程 写时复制

## 混合持久化

aof开始为rdb文件 后续aof重写缓冲区的为aof
优点 结合了2者的优点
缺点 aof可读性差 兼容性差

# redis集群

## 如何实现服务器高可用

多服务节点 如主从复制 哨兵模式 切片集群

### 主从复制

一主多从 读写分离 主负责写然后同步给从 从负责读
主从命令复制异步执行 主服务器在本地执行完写命令就会给客户端返回了 而不需要等到从服务器完成 所以无法实行主从强一致保证（主从数据时刻一致）

### 哨兵模式

监控主从服务器 提供主从节点故障转移
定时向所有服务器发送数据（心跳）主服务器下线后选择新的主服务器

### 切片集群

分布式 类似磁盘阵列
使用hash槽处理数据和节点间的映射关系 而哈希槽和具体的节点之间的对应关系可以平均分配也可以手动分配

## 集群脑裂导致数据丢失

客户端向主服务器发送的写请求在主服务器上执行了 但是主从服务器之间的网络出现异常 哨兵选出了新的主服务器 原来的主服务器重新上线变成了从服务器 被新的主服务器的数据覆盖 客户端写入的数据丢失
解决方案 当主服务器连接到的从服务器数量小于每个值或者与从服务器之间的延迟大于某个值就禁止客户端的写操作

# redis过期删除与内存淘汰

## 过期删除策略

当我们对一个key设置过期时间 redis会将这个key和过期时间存储到过期字典中 当我们查询一个key的时候 redis会首先检查key在不在过期字典中 不在就正常读取 在就检查是否过期
redis采用惰性删除和定期删除的策略

### 惰性删除

不主动删除 从数据库访问key时如果过期再删除 给客户端返回null
优点 cpu占用少 缺点 内存浪费

### 定期删除

每隔一段时间就随机抽一定数量的key 删除其中过期的
流程

1. 从过期字典中随机抽20个
2. 删除其中过期的
3. 如果删除数量大于25% 重复操作
为了避免占用太多时间 默认不超过25ms
优点 一定程度上对cpu和内存的影响达到了平衡
缺点 难以确定时长和频率

## 持久化时对过期key的处理

### rdb

* 生成阶段 会进行过期检查 过期的不会进入rdb
* 加载阶段 主服务器会进行检查 从服务器不会 但是主从服务器会同步 所以一般对主从服务器都不会有影响

## aof

* 写入阶段 没被删除的过期键会被保留 删除后会向aof追加一个显式del命令
* 重写阶段 会进行检查 已过期的键不会被保存

## 主从模式对过期键的处理

从库不会对过期键进行任何处理 所以客户端能读到过期键 主库key到期会向从库的aof追加一条del命令

## redis内存满了会怎么样

运行内存达到最大阈值就会触发内存淘汰机制

## 内存淘汰策略有哪些

1. 不进行内存淘汰 到达最大阈值就报错 默认
2. 在设置了过期时间的键中随机淘汰
3. 在设置了过期时间的键中淘汰最先过期的 （ttl）
4. 在设置了过期时间的键中淘汰最久未使用的 lru
5. 在设置了过期时间的键中淘汰最少使用的 lfu
6. 随机淘汰任意键
7. 淘汰所有键中最久未使用的 lru
8. 淘汰所有键中最少使用的 lfu

## lru和lfu的区别

传统lru的实现基于链表 最新操作的键被移到表头 只要删除表尾的元素即可
缺点

1. 需要用链表管理所有的缓存数据 带来额外空间开销
2. 频繁链表移动操作耗时大
redis并没有采用这样的方式

redis采用了近似lru算法， redis的对象结构体中记录了最后访问时间 进行内存淘汰时 采用随机采样 随机选5个key 淘汰其中最久没有使用的 克服了上述两个缺点
但是lru无法解决缓存污染问题 比如一次读取了大量数据 数据只会被读取一次 这些数据就会留在redis缓存中很久
为了解决这个问题 引入了lfu
lfu会淘汰数据访问次数最少的

# redis缓存设计

## 如何避免缓存雪崩 缓存击穿 缓存穿透

### 避免缓存雪崩

大量缓存数据在同一时间过期
解决方案

1. 将缓存失效时间随机打散 比如在原有失效时间上加一个随机值
2. 设置缓存不过期 通过后台服务更新缓存数据

### 避免缓存击穿

热点数据过期
解决方案 前文提到的两种和

1. 互斥锁 降低并发 redis使用setnx设置一个状态位， 表示锁定状态 未获得互斥锁的请求 要么等待锁释放后读取 要么返回空值或默认值
2. 不给热点数据设置过期时间 由后台异步更新缓存 或者在热点数据快要过期前 通知后台线程更新缓存 重新设置过期时间

### 避免缓存穿透

访问的数据既不在缓存中也不在数据库中
一般有以下原因

1. 业务误操作 数据被误删除
2. 恶意攻击

解决方案

1. 限制非法请求 api入口处判断请求参数是否合理 恶意请求直接返回
错误
2. 设置空值或默认值 针对查询的数据在缓存中设置默认值或者空值
3. 使用布隆过滤器快速判断数据是否存在 写入数据库时用布隆过滤器标记 缓存失效时查询布隆过滤器 不存在直接返回错误 这样大量查询只会查询redis和布隆过滤器

## 设计一个缓存策略 动态缓存热点数据

通过数据最新访问时间排名， 过滤掉不常访问的数据
具体实现 比如要求缓存top1000

1. 先用缓存做一个排序队列 保存1000个id 最近访问的靠前
2. 定期过滤掉最后200名， 再从数据库中随机读出200名加入队列
3. 当请求到达时 从队列获取id 命中再从缓存中读取具体信息并返回

在redis中使用zset 用zadd和zrange完成排序队列和获取200个商品的操作

## 常见缓存更新策略

共有三种

1. cache aside（旁路缓存）
2. read/write through(读/写穿)
3. write back（写回）
实际开发中 redis和mysql更新策略用的cache aside 另外两种用不了

### cache aside

应用直接与缓存 数据库交互 并负责缓存的维护
写策略 先更新数据库 再删除缓存
读策略 如果命中了缓存 直接返回数据 没有命中就查询数据库并更新缓存
写策略采用这样的顺序是因为缓存写入远快于数据库写入 出现数据不一致的可能性极小
此策略适合读多写少的场景 如果写入较频繁 对缓存命中率会有影响
如果对缓存命中率有要求 可以采用如下解决方案

1. 更新数据也更新缓存 但是更新缓存前加一个分布式锁 但是这样对写入性能有一定影响
2. 更新数据也更新缓存， 但是给缓存加一个较短的过期时间，这样即使数据不一致，缓存数据也会很快过期

### read/write through

应用程序只和缓存交互 缓存和数据库交互
read through 查询缓存数据是否存在 存在就直接返回 不存在由缓存负责从数据库查询数据，并将结果写入缓存
write through 有数据更新时 先查询数据是否再缓存中 如果在 更新缓存中的数据 并同步更新数据库 完成后告知应用程序 如果不存在 直接更新数据库
使用较少的原因

* 通常使用分布式缓存 没有提供这些功能 本地缓存可以考虑

### write back

只更新缓存 同时将缓存数据设置为脏的 立马返回 并不同步更新数据库 而是批量异步更新数据库
redis没有这个功能
这种方案在计算机与操作系统中广泛使用 如cpu缓存 操作系统文件系统缓存  
适合写多的场景
问题 数据不是强一致性的 而且有数据丢失风险

# redis实战

## 如何实现延迟队列

延迟队列是指把当前要做的事情 往后推迟一段时间再做 常见使用场景

1. 购物平台下单 超过一定时间未付款 订单自动取消
2. 打车 规定时间没有车主接单 订单会被取消
3. 点外卖 规定时间内没有商家接单 订单会被取消
使用zset实现延迟消息队列 score用来存储延迟执行的时间
用zadd score1 value1往队列中添加成员 用zrangebyscore 查询符合条件的待处理任务 通过不断轮询执行任务

## 大key如何处理

大key并不是说key很大 而是value很大 一般有以下两种情况

1. string值大于10kb
2. hash list set zset元素个数超过5000个

### 大key造成的问题

1. 客户端超时阻塞 因为redis执行命令单线程
2. 网络阻塞 获取大key产生的网络流量大
3. 阻塞工作线程 使用del命令删除大key 会阻塞工作线程
4. 内存分布不均 有大key的redis节点占用内存多

### 如何找到大key

redis-cli --bigkeys命令
注意事项

1. 最好在从服务器上使用 避免阻塞主服务器
2. 如果没有从节点就在低峰期查询，或者使用-i控制扫描间隔 避免长时间扫描降低性能

不足之处

1. 只能返回每种类型最大的key
2. 对于集合类型 只会返回元素数量最多的集合 而这并不一定是占用内存最大的集合
使用scan命令
使用scan命令对数据库进行扫描 用type命令获取返回的key的类型
string类型使用strlen命令获取占用内存的大小
集合类型使用memory usage命令
使用rdbtool工具
通过解析rdb文件获取大于一定大小的key

### 如何删除大key

释放内存只是删除内存的第一步 为了高效管理内存空间 释放内存时操作系统需要将释放掉的内存加入一个空闲内存链表 这个过程需要时间而且会阻塞当前程序
有两种方法

1. 分批次删除
2. 异步删除

分批次删除 对于集合 每次获取其中的100个字段 再一一删除
异步删除 用unlink命令代替del
redis会将key放入异步线程中删除 这是主动调用 还可以配置参数 达
到某些条件时自动异步删除（默认关闭） lazyfree

1. 运行内存超过设定值
2. 键过期
3. 隐式del时
4. 从节点从主节点全量更新前对自己flushall
可以开启前三种 提高主线程执行效率

## redis管道

客户端的批处理技术 提高交互性能解决多个命令执行时的网络等待 把客户端把多个命令整合到一起发送给服务端处理之后再统一返回给客户端
要注意避免发送的命令过大 或管道内数据太多造成网络堵塞
管道技术本质上是客户端提供的功能而非redis服务端的功能

## redis事务支持回滚吗

mysql支持 redis不支持 discard命令可以主动放弃事务执行 把暂存的命令队列清空 但是并不能起到回滚的作用
如果命令入队没有报错 实际执行时出错 正确的命令依然可以正常执行 redis只保证单条命令的原子性
不支持回滚的原因

1. 错误通常都是编程错误 这在生产环境中比较少
2. 这种复杂功能与redis简单高效的设计主旨不符

## 用redis实现分布式锁

分布式锁是分布式环境下并发控制的一种机制 控制某一资源在同一时刻只能被一个应用使用
redis本身可以被多个客户端共享访问 可以用来保存分布式锁 而且redis读写性能高 可以应对高并发的锁操作场景
用 set命令的nx参数 实现key不存在才插入
如果key不存在 显示插入成功 表示加锁成功
如果存在 显示插入失败 表示加锁失败
对于加锁操作 需要满足3种条件

1. 加锁包括读取锁变量， 检查锁变量值， 设置锁变量值三个操作 要以原子方式完成
2. 锁变量要有过期时间，防止异常导致锁一直无法释放，所以要设置过期时间
3. 锁变量的值要能区分来自不同客户端的加锁操作 以免误释放， 所以设置锁变量时，每个客户端设置的值是唯一的
示例命令 set lock_key unique_value nx px 10000
解锁过程就是删除lock——key 为了保证解锁正确客户端，要先判断unique_value是加锁客户端 此时有两个操作 需要使用lua脚本保证原子性

### 优缺点

优点

1. 性能高效 （最核心的优势）
2. 实现方便
3. 避免单点故障 （redis集群）

缺点

1. 超时时间不好设置 太短可能还没执行完操作就被释放掉了 可以启动一个守护进程 当锁快失效时 续约加锁 主线程执行完销毁锁 但是实现比较麻烦
2. 主从复制模式中数据是异步复制的 导致锁的不可靠 比如主节点获取锁 还没同步到从就宕机了 新的主节点依然可以获取到锁

### redis如何解决集群下分布式锁的可靠性

官方设计了redlock算法
基于多个redis节点 即使有节点发生故障 锁变量依然存在 官方推荐至少布置5个redis主节点 基本思路 让客户端和多个独立的redis节点依次申请加锁 如果半数以上都能成功加锁 就认为客户端成功获得了分布式锁
这样一来 即使某个redis节点发生故障，锁也不会丢失
流程

1. 客户端获取当前时间t1
2. 依次向n个节点执行加锁操作 加锁操作本身需要有超时时间 远远小于锁的超时时间 一般几十毫秒
3. 一旦获取了超过半数的锁， 获取当前时间t2 如果t2 - t1小于锁的过期时间 就认为加锁成功
加锁成功后重新计算锁的有效时间 如果已经来不及完成共享数据的操作 就释放锁
加锁失败后 客户端向所有redis节点发起释放锁的操作 使用lua脚本
